---
categories: [Society & Business]
series: [ab]
date: 2026-03-01
lang: en
title: How to Measure ICT Literacy
draft: true
---

Technology is contextual, and hence neither oversimplification nor overcomplication is helpful; it'd be advisable to understand realistic constraints in a very environment and take a tailored approach point by point.

But how can we "understand" real challenges and opportunities a person, organization, community, country, or region faces in the information age? Where are *you* currently at, in terms of digital divide?

One way to accomplish this is travelling to a field, spending time with locals, and co-exploring problems and solutions. Such fieldwork, however, can be resource-intensive, uncertain, and irrelevant to other contexts. Eventually, the work is likely to be unsustainable with a minimum scaling-up potential.

That's where assessment frameworks come in.

### Task-based assessment

By applying a standard set of tasks and measurements globally, institutions are able to gain qualitative and quantitative insights about technology adaptation while eliminating noises. This makes a local reality check and cross-contextual analysis easier.

For example, [ICILS](https://www.iea.nl/studies/iea/icils/) is a worldwide assessment of ICT literacy in educational settings conducted every five years. They employ their standardized questionnaires and virtual hands-on tasks to measure participants' ability to utilize ICT.

ICILS reports provide rich insights about which country scored higher in information search, use of presentation tools (like PowerPoint), and algorithmic games, and how students perceive ICT in their learning journey. It seems like a good baseline framework to monitor the [first- and second-level of the digital divide](/note/digital-divide/), which concerns access and use of digital technologies.

On the other hand, the highly standardized approach decontextualizes the insights by posing the same problem set for a limited number of countries and aggregating the results for the sake of comparison. It won't be fair because each country uses different languages, and students follow different curricula that are likely regulated by its government.

Moreover, assessment in a closed environment makes things unrealistic. By design, the results can be overly simplistic, skewed toward a narrow definition of literacy. They are not generalizable by any means and only dictate one's ability to solve specific, well-documented, synthetic tasks.

To bridge the divide fully, we need more than tools and HOW-TOs. Hence, such task-based lab experiments derive a limited understanding of reality.

### Situational assessment

It's overly simplistic to give a designed task and say, "If you can find Text A on a screen, copy and paste it to Box X, and guess what to do next, you are digitally prepared."

Why? Because readiness, in reality, is more psychological and situational.

Even if he/she uses an Android smartphone daily for social media, they won't be ready to enjoy what ICT offers to the fullest as long as there is psychological friction, like, "Am I doing the right thing?"

Or, one can gain confidence to use technology only when they are in a certain situation, where they can objectively confirm how advanced they are by seeing others' behaviour.

That's the concept situational assessment frameworks, like [Technology Readiness Index](https://journals.sagepub.com/doi/10.1177/109467050024001) (TRI) and [TRI 2.0](https://journals.sagepub.com/doi/abs/10.1177/1094670514539730), stand for. The idea is to measure prosperity by using technology, not skills.

TRI asks a series of situational questions, which are classified into the following four categories to measure various contextualized factors pushing/hindering technology adaptation.

1. **Optimism**: Do you have a positive view of technology?
    - Ex. "Technology gives me more freedom of mobility."
2. **Innovativeness**: Is there a tendency for you to be a leader in tech?
    - Ex. "Other people come to me for advice on new technologies."
3. **Discomfort**: Do you experience the lack of control over tech and feeling discomfort?
    - Ex. "In my circle of friends, people are admired more if they own the latest gadgets."
4. **Insecurity**: Do you have skepticism if tech works appropriately?
    - Ex. "I do not feel confident doing business with a place that can only be reached online."

By asking whether subjects agree or disagree with each statement, we get access to a more contextualized and less filtered understanding of the state of literacy.
