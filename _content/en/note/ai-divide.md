---
categories: [Business]
series: [ab, ai]
date: 2026-02-01
lang: en
title: The AI Divide
images: [/images/thumbnails/divide.jpg]
keywords: [humans, isting, divide, technology, smarter, contexts, tools, problems,
  need, inequality]
recommendations: [/note/offline-learning/, /note/digital-divide/, /note/one-year-in-malawi/]
---

People worldwide exhibit varying levels of excitement or concern about AI, from the rich to the poor, ordinary citizens to global leaders to politicians, regardless of their occupation and industry. One cannot avoid the wave, even if "I'm not an expert" or "I don't use computers."

Therefore, before further investing in the technology, it is essential for each one of us to face reality, understand both the benefits and risks, and make informed and intentional decisions.

To be more precise, I often start my conversation with clients and audiences by highlighting the following points:

- AI, like any other technology, is context-dependent.
- AI represents the existing power dynamics and inequality.
- AI can deepen the digital divide, if not accompanied by users' ability to think critically and solve complex problems.

First, the impact of technology use depends heavily on the context.

AI in Egypt and Uganda, for example, requires different approaches depending on the countries' demographic, geographical, political, cultural, societal, and economic conditions. Even within the same country, rural-urban inequalities block one-size-fits-all technological interventions. In the end, *you* and *I* always want separate prescriptions for technological advancement.

The problem is that, when we naively say "AI," it suppresses these contexts.

When I ask stakeholders about how they define AI, they describe it as ChatGPT or some kind of applications that help us generate images, videos, music, and text. Some may bring up innovative tools in specific industries.

So, I follow up: "Why do you need AI?" Often, I don't get much clarity, other than the fact that the rest of the world is talking about it, so am I. I also hear claims that it makes us more productive. But productivity for what? How fast and efficient should humans become? How far do you want to go?

In any case, **end users tend to perceive the technology in an extremely narrow and generic sense**, and there is almost certainly no logical explanation of why there is a need for AI.

On the one hand, wrapping problems and solutions by common sense is easy and convenient. A decade ago, I spent a hard time explaining the motivation and impact of algorithmic recommendations and predictive modeling to academic and business audiences. But today, as long as I say "This is an AI for \[whatever problems you can imagine\]," the conversation will move on. It's so effortless and easy to neglect my duty as a developer.

On the other hand, poorly examined vocabulary oversimplifies the worldâ€™s multifaceted problems, gives decision-makers permission to skip the essential questions, and makes simpler solutions invisible. Seeing the gap as an opportunity, some might consider the need for [small AI](https://blogs.worldbank.org/en/voices/small-ai-big-impact-harnessing-artificial-intelligence-for-development), although the underlying motivation is still bound by market trends. Eventually, such **externally driven changes favour speculative capital over people**, making the rich richer in a capitalist society.

That is the second point about the representation of the existing inequality.

By nature, AI development requires a significant amount of resources in terms of computation, human labour, and money. Thus, countries, companies, or individuals who already have those resources continue to enjoy the advantage, while others first need to tackle the deep economic and political challenges to enter the field.

Meanwhile, [data biases](/note/data-feminism/) are real. And they are rooted in the history of English-centered, male-dominated, white supremacy. Unless we optimize our approach for marginalized contexts, AI policies and applications tend to converge on a skewed state where AI development incentivizes wealthy people's self-centered acts.

That is, **joining the AI race is practically a form of approval for today's world as it is**, pushing the [AI divide](https://www.ilo.org/publications/major-publications/mind-ai-divide-shaping-global-perspective-future-work) backed by the [uneven growth](https://blogs.worldbank.org/en/voices/global-economic-resilience-masks-an-uneven-growth-outlook).

Furthermore, the ignorance of people and their contexts not only surfaces the power imbalance but amplifies it. AI is a kind of digital application, and the world has yet to bridge the digital divide. Hence, careless introduction of AI tools simply adds an extra layer of complexity to the existing problem, leaving digitally unprepared populations further behind.

As the [3rd level of digital divide](/note/digital-divide/)&mdash;lack of outcome-focused, critical use of digital technology&mdash;becomes more tangible, AI applications need to be integrated with personal traits so that they make humans [smarter, not *look* smarter](https://blogs.worldbank.org/en/education/is-ai-making-us-smarter-or-just-making-us-look-smart-). Providing access to the tools and cultivating relevant skills are insufficient.

Examining AI through the lens of the digital divide helps us understand its implications. And the **AI divide shows the fundamental issue and untapped possibilities our world holds**, which cannot be described by a mere use of the trending word.

Ultimately, the technology is implemented by humans, deployed by humans, and used by humans. So, why AI?
